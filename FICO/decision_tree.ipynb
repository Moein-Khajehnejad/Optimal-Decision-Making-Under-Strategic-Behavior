{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "accepted_data = pd.read_csv(\"data/accepted_2007_to_2018Q4.csv\", usecols = ['last_fico_range_high','last_fico_range_low','loan_amnt','dti','zip_code','addr_state','emp_length','loan_status'],nrows=4000)\n",
    "rejected_data = pd.read_csv(\"data/rejected_2007_to_2018Q4.csv\",usecols = ['Amount Requested', 'Debt-To-Income Ratio', 'Zip Code', 'State', 'Employment Length','Risk_Score'],nrows =4000)\n",
    "num_of_accepted = len(accepted_data)\n",
    "num_of_rejected = len(rejected_data)\n",
    "\n",
    "\n",
    "accepted_data = accepted_data.dropna(axis=0)\n",
    "rejected_data = rejected_data.dropna(axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/myenv/lib/python3.5/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#Calculate the feature from accepted data equivalent to \"risk factor\" in rejected data : mean of fico scores\n",
    "cols = ['last_fico_range_high','last_fico_range_low']\n",
    "Fico_mean = accepted_data[cols].astype(float).mean(axis=1) \n",
    "\n",
    "#add the new feature to accepted data\n",
    "accepted_data_tmp = accepted_data.copy()\n",
    "accepted_data_tmp['fico_mean'] = Fico_mean\n",
    "accepted_data_new = accepted_data_tmp[['loan_amnt','dti','zip_code','addr_state','emp_length','fico_mean','loan_status']]\n",
    "\n",
    "#Categorize accepted data by the loan status: Fully Paid =1, Charged Off, Default =0, else = remove rows\n",
    "accepted_data_new.loan_status = accepted_data_new.loan_status.replace(['Fully Paid', 'Charged Off' , 'Default'] , [1,0,0])\n",
    "\n",
    "#Remove rows that have values other than 'Fully Paid', 'Charged Off' , 'Current'\n",
    "values_valid = [0,1]\n",
    "accepted_data_new = accepted_data_new[accepted_data_new.loan_status.isin(values_valid)]\n",
    "#print(accepted_data_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choosing the features from rejected-data\n",
    "rejected_data_tmp = rejected_data.copy()\n",
    "rejected_data_new = rejected_data_tmp[['Amount Requested', 'Debt-To-Income Ratio', 'Zip Code', 'State', 'Employment Length','Risk_Score']]\n",
    "\n",
    "#Change the column headers to match the columns of accepted_data_new\n",
    "rejected_data_new.columns = ['loan_amnt','dti','zip_code','addr_state','emp_length','fico_mean']\n",
    "\n",
    "#Compute Fico scroe from Risk scores\n",
    "rejected_data_new['fico_mean'] =  850 - rejected_data_new['fico_mean']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dealing with strings in the features\n",
    "rejected_data_new['dti'] = rejected_data_new.dti.str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "rejected_data_new['zip_code'] = rejected_data_new.zip_code.str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "rejected_data_new['emp_length'] = rejected_data_new.emp_length.str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "\n",
    "accepted_data_new['zip_code'] = accepted_data_new.zip_code.str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "accepted_data_new['emp_length'] = accepted_data_new.emp_length.str.extract(r'(\\d+)', expand=True).astype(int)\n",
    "\n",
    "#Extract size of each accepted or rejected data\n",
    "num_of_accepted = len(accepted_data_new)\n",
    "num_of_rejected = len(rejected_data_new)\n",
    "\n",
    "#Remove the \"loan_status\" column for the concatenation of all data\n",
    "accepted_tmp = accepted_data_new[['loan_amnt','dti','zip_code','addr_state','emp_length','fico_mean']]\n",
    "\n",
    "#Concatenate all data to do the numerization of the categorical data for all homogeneously\n",
    "all_data = pd.concat([accepted_tmp,rejected_data_new])\n",
    "\n",
    "#Change the categorical feature \"addr_state\" to numerical feature\n",
    "address_state = all_data['addr_state'].unique().tolist()\n",
    "all_data['addr_state'] = all_data['addr_state'].apply( lambda x : address_state.index(x))\n",
    "\n",
    "#print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Separate accepted and rejected dat after homogenizing all features\n",
    "processed_data_accepted = all_data[0:num_of_accepted]\n",
    "processed_data_accepted = processed_data_accepted.astype('int')\n",
    "\n",
    "processed_data_rejected = all_data[num_of_accepted:]\n",
    "processed_data_rejected = processed_data_rejected.astype('int')\n",
    "\n",
    "#target values for calssification: loan_status column\n",
    "target = accepted_data_new.loan_status\n",
    "target = target.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores: [0.92529586 0.92159763 0.92899408 0.92455621 0.91568047 0.91420118\n",
      " 0.91789941 0.92455621 0.92381657 0.9260355 ]\n",
      "[[0.2755102  0.7244898 ]\n",
      " [0.00263852 0.99736148]\n",
      " [0.00263852 0.99736148]\n",
      " ...\n",
      " [0.00263852 0.99736148]\n",
      " [0.17692308 0.82307692]\n",
      " [0.92990654 0.07009346]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accepted_data.pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle data\n",
    "cv = ShuffleSplit(n_splits= 10, test_size=0.4, random_state=0)\n",
    "\n",
    "#Design a decision tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4,min_samples_leaf=6,min_samples_split=4)\n",
    "\n",
    "#Perform cross validation and calculate the score \n",
    "score = cross_val_score(clf, processed_data_accepted, target, cv=cv)\n",
    "print('cross validation scores:',score)\n",
    "\n",
    "#Fit the model on the data to later visualize the designed tree\n",
    "clf_fitted = clf.fit(processed_data_accepted, target)\n",
    "predictions_accepted = clf_fitted.predict_proba(processed_data_accepted)\n",
    "print(predictions_accepted)\n",
    "\n",
    "#Visualize the tree\n",
    "##Comment out if graphviz not installed\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=processed_data_accepted.columns,class_names=['0','1'],filled=True, rounded=True,special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph\n",
    "graph.render(\"accepted_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20122756919972912\n",
      "0.5655555555555556\n"
     ]
    }
   ],
   "source": [
    "#Set the constant 'c'\n",
    "#Apply the designed tree on the rejected data\n",
    "predictions_rejected = clf_fitted.predict_proba(processed_data_rejected)\n",
    "rejected_probs  = predictions_rejected[:,1]\n",
    "print(np.mean(rejected_probs))\n",
    "c = (np.percentile(rejected_probs,95))+0.01\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.29004535  0.15893424]\n",
      " [-0.56291703  0.43180592]\n",
      " [-0.56291703  0.43180592]\n",
      " ...\n",
      " [-0.56291703  0.43180592]\n",
      " [-0.38863248  0.25752137]\n",
      " [ 0.36435099 -0.4954621 ]]\n",
      "[[-0.12111111 -0.01      ]\n",
      " [-0.12111111 -0.01      ]\n",
      " [ 0.36435099 -0.4954621 ]\n",
      " ...\n",
      " [ 0.36435099 -0.4954621 ]\n",
      " [ 0.36435099 -0.4954621 ]\n",
      " [-0.12111111 -0.01      ]]\n"
     ]
    }
   ],
   "source": [
    "#Compute 'utility' values\n",
    "utility_accepted = predictions_accepted -c\n",
    "print(utility_accepted)\n",
    "\n",
    "utility_rejected = predictions_rejected -c\n",
    "print(utility_rejected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf = clf.fit(X, Y)\n",
    "#clf.predict_proba([[2., 2.]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
